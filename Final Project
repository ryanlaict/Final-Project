{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOt4NpFYbAHhVPh7mGG8Pmb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"n6iIUbHO-tqT"},"outputs":[],"source":["import torch  # PyTorch for deep learning operations\n","import transformers  # Hugging Face Transformers library for pre-trained models\n","import numpy as np  # NumPy for numerical computations\n","import pandas as pd  # Pandas for data manipulation and analysis\n","\n","import nltk  # Natural Language Toolkit for text processing tasks\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from collections import Counter  # For counting word frequencies\n","import re  # Regular expressions for text cleaning and pattern matching\n","from transformers import (\n","    AutoModelForSequenceClassification,  # Example model for classification\n","    AutoTokenizer,  # Tokenizer for pre-trained models\n","    TrainingArguments,  # Configuration for training\n","    Trainer,  # Training loop and evaluation\n",")\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support  # Evaluation metrics"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RpQFybqmEGp","executionInfo":{"status":"ok","timestamp":1743464790338,"user_tz":420,"elapsed":21348,"user":{"displayName":"Ryan Lai","userId":"17312964168471201634"}},"outputId":"38f167e9-16f3-4ad2-e0e7-cd229bf86863"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cp '/content/drive/MyDrive/<path-to-notebook-in-drive>' '<Finap Project.ipynb>'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mn95vAr6mXe-","executionInfo":{"status":"ok","timestamp":1743464809117,"user_tz":420,"elapsed":831,"user":{"displayName":"Ryan Lai","userId":"17312964168471201634"}},"outputId":"01117616-823f-4788-c613-ff231bd2063a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Final-Project'...\n","warning: You appear to have cloned an empty repository.\n"]}]},{"cell_type":"code","source":["wnba_data = pd.read_csv('/content/wnba_data.csv')\n","wnba_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"Q1b84x73_Dvn","executionInfo":{"status":"error","timestamp":1743463971182,"user_tz":420,"elapsed":238,"user":{"displayName":"Ryan Lai","userId":"17312964168471201634"}},"outputId":"bedbe144-3a98-468b-ed89-c2d287a2db2e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/wnba_data.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-1e224609bc9a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwnba_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/wnba_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwnba_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/wnba_data.csv'"]}]},{"cell_type":"code","source":["nba_data = pd.read_csv('/content/nba_regular_season.csv', encoding='latin-1', delimiter=\";\")\n","nba_data.head()"],"metadata":{"id":"h4ahd6m-_cya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create WNBA Teams:\n","\n","import pandas as pd\n","\n","# Define the data as a list of lists\n","wnba_data = [\n","    ['Atlanta', 'Atl', 'Atlanta Dream (2008 - present)'],\n","    ['Charlotte', 'Cha', 'Charlotte Sting (1997 - 2006)'],\n","    ['Chicago', 'Chi', 'Chicago Sky (2006 - present)'],\n","    ['Cleveland', 'Cle', 'Cleveland Rockers (1997 - 2003)'],\n","    ['Connecticut', 'Con', 'Connecticut Sun (2003 - present)'],\n","    ['Dallas', 'Dal', 'Dallas Wings (2016 - present)'],\n","    ['Detroit', 'Det', 'Detroit Shock (1998 - 2009)'],\n","    ['San Francisco', 'Hou', 'Golden State Valkyries (2025 - present)'],\n","    ['Houston', 'Hou', 'Houston Comets (1997 - 2008)'],\n","    ['Indiana', 'Ind', 'Indiana Fever (2000 - present)'],\n","    ['Las Vegas', 'LV', 'Las Vegas Aces (2018 - present)'],\n","    ['Los Angeles', 'LA', 'Los Angeles Sparks (1997 - present)'],\n","    ['Miami', 'Mia', 'Miami Sol (2000 - 2002)'],\n","    ['Minnesota', 'Min', 'Minnesota Lynx (1999 - present)'],\n","    ['New York', 'NY', 'New York Liberty (1997 - present)'],\n","    ['Orlando', 'Orl', 'Orlando Miracle (1999 - 2002)'],\n","    ['Phoenix', 'Phx', 'Phoenix Mercury (1997 - present)'],\n","    ['Portland', 'Por', 'Portland Fire (2000 - 2002)'],\n","    ['Sacramento', 'Sac', 'Sacramento Monarchs (1997 - 2009)'],\n","    ['San Antonio', 'SA', 'San Antonio Silver Stars (2003 - 2017)'],\n","    ['Tulsa', 'Tul', 'Tulsa Shock (2010 - 2015)'],\n","    ['Utah', 'Uta', 'Utah Starzz (1997 - 2002)'],\n","    ['Washington', 'Wsh', 'Washington Mystics (1998 - present)']\n","]\n","\n","# Create a Pandas DataFrame\n","wnba_df = pd.DataFrame(wnba_data, columns=['City', 'Abbreviation', 'Team'])\n","\n","# Display the table\n","wnba_df"],"metadata":{"id":"DbJbcRKnBgu7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wnba_df['Abbreviation'] = wnba_df['Abbreviation'].str.upper()\n","wnba_df"],"metadata":{"id":"WozJS0gpAfNR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Define the data as a list of lists or a dictionary\n","data = [\n","    ['ATL', 'Atlanta Dream'],\n","    ['CHI', 'Chicago Sky'],\n","    ['CON', 'Connecticut Sun'],\n","    ['DAL', 'Dallas Wings'],\n","    ['IND', 'Indiana Fever'],\n","    ['LV', 'Las Vegas Aces'],\n","    ['LAS', 'Los Angeles Sparks'],\n","    ['MIN', 'Minnesota Lynx'],\n","    ['NYL', 'New York Liberty'],\n","    ['PHO', 'Phoenix Mercury'],\n","    ['SEA', 'Seattle Storm'],\n","    ['WAS', 'Washington Mystics'],\n","]\n","\n","# Or, using a dictionary:\n","# data = {\n","#     'Abbreviation': ['ATL', 'CHI', 'CON', 'DAL', 'IND', 'LV', 'LAS', 'MIN', 'NYL', 'PHO', 'SEA', 'WAS'],\n","#     'Team': ['Atlanta Dream', 'Chicago Sky', 'Connecticut Sun', 'Dallas Wings', 'Indiana Fever', 'Las Vegas Aces', 'Los Angeles Sparks', 'Minnesota Lynx', 'New York Liberty', 'Phoenix Mercury', 'Seattle Storm', 'Washington Mystics']\n","# }\n","\n","# Create a Pandas DataFrame\n","wnba_teams_df = pd.DataFrame(data, columns=['Abbreviation', 'Team'])\n","\n","# Display the table\n","wnba_teams_df"],"metadata":{"id":"VdWLW_mGCvuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the 'Team' column into separate columns based on the bracket\n","wnba_df[['Team_Start', 'Team_End']] = wnba_df['Team'].str.split('(', expand=True)\n","wnba_df['Team_End'] = wnba_df['Team_End'].str.replace(')', '', regex=False)\n","\n","# Display the updated DataFrame\n","wnba_df.drop(columns=['Team_End'], inplace=True)\n","wnba_df\n"],"metadata":{"id":"WRbERx4-C8yV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wnba_df"],"metadata":{"id":"Q4ZU_WZ4YBtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_df = pd.merge(wnba_data,wnba_df , left_on='Team', right_on='Abbreviation')\n","merged_df.head()"],"metadata":{"id":"V2ngHRPLEGU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_df_dropped = merged_df.drop(columns=['Abbreviation','Team_y'])\n","merged_df_dropped.head()"],"metadata":{"id":"72lsMQ9Fw7Xk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_df_dropped.shape"],"metadata":{"id":"FhoM2kXWxCGy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mkaj8z97I6Y8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(merged_df.shape)\n","print(nba_merged_dropped.shape)"],"metadata":{"id":"hUpbZRttYb67"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nba_merge.columns"],"metadata":{"id":"wcTrNq_JxQyo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_df.columns"],"metadata":{"id":"DWhXwE31xWHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  merged_df.describe()"],"metadata":{"id":"b5HIDAPQZ8bM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Define the data\n","data = {\n","    \"Team Name\": [\n","        \"Atlanta Hawks\", \"Boston Celtics\", \"Brooklyn Nets\", \"Charlotte Hornets\", \"Chicago Bulls\",\n","        \"Cleveland Cavaliers\", \"Dallas Mavericks\", \"Denver Nuggets\", \"Detroit Pistons\", \"Golden State Warriors\",\n","        \"Houston Rockets\", \"Indiana Pacers\", \"Los Angeles Clippers\", \"Los Angeles Lakers\", \"Memphis Grizzlies\",\n","        \"Miami Heat\", \"Milwaukee Bucks\", \"Minnesota Timberwolves\", \"New Orleans Pelicans\", \"New York Knicks\",\n","        \"Oklahoma City Thunder\", \"Orlando Magic\", \"Philadelphia 76ers\", \"Phoenix Suns\", \"Portland Trail Blazers\",\n","        \"Sacramento Kings\", \"San Antonio Spurs\", \"Toronto Raptors\", \"Utah Jazz\", \"Washington Wizards\"\n","    ],\n","    \"Abbreviation\": [\n","        \"ATL\", \"BOS\", \"BKN\", \"CHA\", \"CHI\", \"CLE\", \"DAL\", \"DEN\", \"DET\", \"GSW\",\n","        \"HOU\", \"IND\", \"LAC\", \"LAL\", \"MEM\", \"MIA\", \"MIL\", \"MIN\", \"NOP\", \"NYK\",\n","        \"OKC\", \"ORL\", \"PHI\", \"PHX\", \"POR\", \"SAC\", \"SAS\", \"TOR\", \"UTA\", \"WAS\"\n","    ],\n","    \"City\": [\n","        \"Atlanta\", \"Boston\", \"Brooklyn\", \"Charlotte\", \"Chicago\", \"Cleveland\", \"Dallas\", \"Denver\", \"Detroit\", \"San Francisco\",\n","        \"Houston\", \"Indianapolis\", \"Los Angeles\", \"Los Angeles\", \"Memphis\", \"Miami\", \"Milwaukee\", \"Minneapolis\",\n","        \"New Orleans\", \"New York City\", \"Oklahoma City\", \"Orlando\", \"Philadelphia\", \"Phoenix\", \"Portland\",\n","        \"Sacramento\", \"San Antonio\", \"Toronto\", \"Salt Lake City\", \"Washington\"\n","    ],\n","    \"State/Province\": [\n","        \"Georgia\", \"Massachusetts\", \"New York\", \"North Carolina\", \"Illinois\", \"Ohio\", \"Texas\", \"Colorado\", \"Michigan\", \"California\",\n","        \"Texas\", \"Indiana\", \"California\", \"California\", \"Tennessee\", \"Florida\", \"Wisconsin\", \"Minnesota\",\n","        \"Louisiana\", \"New York\", \"Oklahoma\", \"Florida\", \"Pennsylvania\", \"Arizona\", \"Oregon\",\n","        \"California\", \"Texas\", \"Ontario (Canada)\", \"Utah\", \"D.C.\"\n","    ]\n","}\n","\n","# Create the DataFrame\n","nba_teams_df = pd.DataFrame(data)\n","\n","# Display the DataFrame\n","print(nba_teams_df)\n"],"metadata":{"id":"BZspYdq1DwDo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nba_merge = pd.merge(nba_data, nba_teams_df, left_on='Tm', right_on='Abbreviation', how='left')\n","nba_merge.head()"],"metadata":{"id":"RrVg_DM6F2Cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nba_merged_dropped = nba_merge.drop(columns=['Abbreviation','Rk','State/Province', 'Age','eFG%','DRB'])\n","nba_merged_dropped.head()"],"metadata":{"id":"RBinGB1lxIwW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nba_merged_dropped['Player']"],"metadata":{"id":"Waen5cYpVnd9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nba_merged_dropped = nba_merged_dropped.rename(columns={'Tm': 'Team'}, )\n","nba_merged_dropped.head()"],"metadata":{"id":"8x2g4zyCIcsC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_df.head()"],"metadata":{"id":"0HMHEQ81LM6_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_df_dropped = merged_df.drop(columns=['Abbreviation','Team_y', 'G.1','MP.1'])\n","merged_df_dropped.head()"],"metadata":{"id":"q1gi-8uVLGHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_df_dropped = merged_df_dropped.rename(columns={'Team_x': 'Team','Team_Start': 'Team Name' })\n","merged_df_dropped.head()"],"metadata":{"id":"BQOOY6YuLCP7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(merged_df_dropped)"],"metadata":{"id":"nLDssM7nlvPv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_df = pd.concat([merged_df_dropped, nba_merged_dropped], axis=0)\n","combined_df.head()"],"metadata":{"id":"8Md413VDnWYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(merged_df_dropped.columns)\n","print(nba_merged_dropped.columns)"],"metadata":{"id":"1fNqKHNhDAJM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure all shared columns are in the same order\n","common_columns = [\n","    'Player', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%',\n","    '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'TRB', 'AST', 'STL', 'BLK', 'TOV',\n","    'PF', 'PTS', 'City','Team Name'\n","]\n","\n","\n","# Reorder columns for consistency\n","nba_df = nba_merged_dropped[common_columns]\n","wnba_df = merged_df_dropped[common_columns]"],"metadata":{"id":"mwXCwjeqIVaW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define position mapping\n","position_mapping = {\n","    'PG': 'G',\n","    'SG': 'G',\n","    'PG-SG': 'G',\n","    'SG-PG': 'G',\n","    'SF': 'F',\n","    'SF-PF': 'F',\n","    'PF-SF': 'F',\n","    'PF': 'F',\n","    'C': 'C',\n","    'F': 'F',\n","    'F-C': 'F-C',\n","    'C-PF': 'F-C',\n","    'PF-C': 'F-C',\n","    'G': 'G',\n","    'G-F': 'G-F',\n","    'C-F': 'F-C',\n","}\n","\n","# Apply the mapping\n","nba_merged_dropped['Pos'] = nba_merged_dropped['Pos'].map(position_mapping).fillna(nba_merged_dropped['Pos'])\n","merged_df_dropped['Pos'] = merged_df_dropped['Pos'].map(position_mapping).fillna(merged_df_dropped['Pos'])\n","\n","# Verify the changes\n","print(nba_merged_dropped['Pos'].unique())\n","print(merged_df_dropped['Pos'].unique())\n"],"metadata":{"id":"0TZotpefR_0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numerical_columns = combined_df.select_dtypes(include=[np.number]).columns.tolist()"],"metadata":{"id":"bNjIhJ82Mc6j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numerical_columns"],"metadata":{"id":"w0Wdy4lmO1um"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"zmpQDkv3NhlM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nba_merged_dropped[\"League\"] = \"NBA\"\n","merged_df_dropped[\"League\"] = \"WNBA\""],"metadata":{"id":"SLh9siLjPuf6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_df_dropped.head()"],"metadata":{"id":"rr7R1UzyS7k0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure all shared columns are in the same order\n","common_columns = [\n","    'Player', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%',\n","    '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'TRB', 'AST', 'STL', 'BLK', 'TOV',\n","    'PF', 'PTS', 'City','Team Name','League'\n","]\n","\n","\n","# Reorder columns for consistency\n","nba_df = nba_merged_dropped[common_columns]\n","wnba_df = merged_df_dropped[common_columns]"],"metadata":{"id":"Bv-KFqcjTOFy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_data = pd.concat([nba_merged_dropped, merged_df_dropped], axis=0)"],"metadata":{"id":"etxHdrlUTQ7W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_data"],"metadata":{"id":"13qvQJp7TZkI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numerical_columns = combined_data.select_dtypes(include=[np.number]).columns.tolist()"],"metadata":{"id":"fg0l9rjETpTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-k3_OC4-TtCR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","# Step 1: Identify numerical columns (exclude non-numerical columns)\n","numerical_columns = combined_data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n","\n","# Exclude non-numeric columns like 'Player', 'League', etc. (if needed)\n","numerical_columns = [col for col in numerical_columns if col not in ['Player', 'League']]\n","\n","# Step 2: Initialize the scaler\n","scaler = StandardScaler()\n","\n","# Step 3: Fit and transform the numerical data (scale only the numerical columns)\n","scaled_numerical_data = scaler.fit_transform(combined_data[numerical_columns])\n","\n","# Step 4: Convert the scaled data back to a DataFrame\n","scaled_numerical_df = pd.DataFrame(scaled_numerical_data, columns=numerical_columns)\n","\n","# Step 5: Reintegrate with non-numerical columns (e.g., 'Player', 'League')\n","scaled_combined_data = combined_data.copy()\n","scaled_combined_data[numerical_columns] = scaled_numerical_df\n","\n","print(\"Data Scaling Complete!\")\n","print(scaled_combined_data.head())\n"],"metadata":{"id":"EFHW-wngNRle"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","categorical_columns =['Pos', 'Team', 'Team Name', 'City', 'League']\n","\n","# One-hot encode for both datasets\n","combined_data_encoded = pd.get_dummies(scaled_combined_data, columns=categorical_columns)\n","\n","\n"],"metadata":{"id":"m8yuQvbyOfS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["categorical_columns"],"metadata":{"id":"I6H8rEZHQ8mf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_data_encoded.head()"],"metadata":{"id":"3nc7FFMUOp5q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Compute similarity across all players (NBA + WNBA)\n","similarity_matrix = cosine_similarity(combined_data_encoded[numerical_columns])\n","\n","# Convert to DataFrame with Player names as index & columns\n","similarity_df = pd.DataFrame(similarity_matrix, index=combined_data_encoded['Player'], columns=combined_data_encoded['Player'])\n","\n","print(\"Similarity Matrix Shape:\", similarity_df.shape)\n"],"metadata":{"id":"b9yNhHQNQfGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Separate NBA and WNBA players\n","nba_players = combined_data_encoded[combined_data_encoded[\"League_NBA\"] == 1][\"Player\"]\n","wnba_players = combined_data_encoded[combined_data_encoded[\"League_WNBA\"] == 1][\"Player\"]\n","\n","# Ensure that the player names in nba_players and wnba_players match the index/columns in similarity_df\n","# Extract NBA → WNBA similarities from the similarity matrix\n","nba_to_wnba_similarity = similarity_df.loc[nba_players, wnba_players]\n","\n","# Output the shape of the NBA-to-WNBA similarity matrix\n","print(\"NBA-to-WNBA Similarity Matrix Shape:\", nba_to_wnba_similarity.shape)\n"],"metadata":{"id":"pwZSoBy5UtHj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def recommend_wnba_players(nba_player, top_n=5):\n","    if nba_player not in nba_to_wnba_similarity.index:\n","        return \"Player not found in dataset.\"\n","\n","    # Get similarity scores for the given NBA player\n","    similar_wnba_players = nba_to_wnba_similarity.loc[nba_player].sort_values(ascending=False).head(top_n)\n","\n","    return similar_wnba_players\n","\n","# Example: Recommend WNBA players for Stephen Curry\n","print(recommend_wnba_players(\"Jayson Tatum\"))\n"],"metadata":{"id":"6lJgP5VyUuPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vfRe1894Vf55"},"execution_count":null,"outputs":[]}]}